@article{lecun1989backpropagation,
  title={Backpropagation applied to handwritten zip code recognition},
  author={LeCun, Yann and Boser, Bernhard and Denker, John S and Henderson, Donnie and Howard, Richard E and Hubbard, Wayne and Jackel, Lawrence D},
  journal={Neural computation},
  volume={1},
  number={4},
  pages={541--551},
  year={1989},
  publisher={MIT Press}
}

@article{lecun1998gradient,
  title={Gradient-based learning applied to document recognition},
  author={LeCun, Yann and Bottou, L{\'e}on and Bengio, Yoshua and Haffner, Patrick},
  journal={Proceedings of the IEEE},
  volume={86},
  number={11},
  pages={2278--2324},
  year={1998},
  publisher={Ieee}
}

@article{ji20123d,
  title={{3D} convolutional neural networks for human action recognition},
  author={Ji, Shuiwang and Xu, Wei and Yang, Ming and Yu, Kai},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={35},
  number={1},
  pages={221--231},
  year={2012},
  publisher={IEEE}
}

@inproceedings{xu2015show,
  title={Show, attend and tell: Neural image caption generation with visual attention},
  author={Xu, Kelvin and Ba, Jimmy and Kiros, Ryan and Cho, Kyunghyun and Courville, Aaron and Salakhudinov, Ruslan and Zemel, Rich and Bengio, Yoshua},
  booktitle={International conference on machine learning},
  pages={2048--2057},
  year={2015},
  organization={PMLR}
}

@article{ye2019two,
  title={Two-stream convolutional network for improving activity recognition using convolutional long short-term memory networks},
  author={Ye, W and Cheng, Jingjng and Yang, Feng and Xu, Yikai},
  journal={IEEE Access},
  volume={7},
  pages={67772--67780},
  year={2019},
  publisher={IEEE}
}

@inproceedings{wang2016temporal,
  title={Temporal segment networks: Towards good practices for deep action recognition},
  author={Wang, Limin and Xiong, Yuanjun and Wang, Zhe and Qiao, Yu and Lin, Dahua and Tang, Xiaoou and Van Gool, Luc},
  booktitle={European conference on computer vision},
  pages={20--36},
  year={2016},
  organization={Springer}
}

@inproceedings{sudhakaran2019lsta,
  title={{LSTA}: Long short-term attention for egocentric action recognition},
  author={Sudhakaran, Swathikiran and Escalera, Sergio and Lanz, Oswald},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={9954--9963},
  year={2019}
}

@article{shi2015convolutional,
  title={Convolutional {LSTM} network: A machine learning approach for precipitation nowcasting},
  author={Shi, Xingjian and Chen, Zhourong and Wang, Hao and Yeung, Dit-Yan and Wong, Wai-Kin and Woo, Wang-chun},
  journal={arXiv preprint arXiv:1506.04214},
  year={2015}
}

@article{sudhakaran2018attention,
  title={Attention is all we need: Nailing down object-centric attention for egocentric activity recognition},
  author={Sudhakaran, Swathikiran and Lanz, Oswald},
  journal={arXiv preprint arXiv:1807.11794},
  year={2018}
}

@inproceedings{farneback2003two,
  title={Two-frame motion estimation based on polynomial expansion},
  author={Farneb{\"a}ck, Gunnar},
  booktitle={Scandinavian conference on Image analysis},
  pages={363--370},
  year={2003},
  organization={Springer}
}

@article{perez2013tv,
  title={{TV-L1} optical flow estimation},
  author={P{\'e}rez, Javier S{\'a}nchez and Meinhardt-Llopis, Enric and Facciolo, Gabriele},
  journal={Image Processing On Line},
  volume={2013},
  pages={137--150},
  year={2013}
}

@incollection{hur2020optical,
  title={Optical Flow Estimation in the Deep Learning Age},
  author={Hur, Junhwa and Roth, Stefan},
  booktitle={Modelling Human Motion},
  pages={119--140},
  year={2020},
  publisher={Springer}
}

@article{bahdanau2014neural,
  title={Neural machine translation by jointly learning to align and translate},
  author={Bahdanau, Dzmitry and Cho, Kyunghyun and Bengio, Yoshua},
  journal={arXiv preprint arXiv:1409.0473},
  year={2014}
}

@inproceedings{damen2018scaling,
  title={Scaling egocentric vision: The epic-kitchens dataset},
  author={Damen, Dima and Doughty, Hazel and Farinella, Giovanni Maria and Fidler, Sanja and Furnari, Antonino and Kazakos, Evangelos and Moltisanti, Davide and Munro, Jonathan and Perrett, Toby and Price, Will and others},
  booktitle={Proceedings of the European Conference on Computer Vision (ECCV)},
  pages={720--736},
  year={2018}
}

@article{damen2020rescaling,
  title={Rescaling egocentric vision},
  author={Damen, Dima and Doughty, Hazel and Farinella, Giovanni Maria and Furnari, Antonino and Kazakos, Evangelos and Ma, Jian and Moltisanti, Davide and Munro, Jonathan and Perrett, Toby and Price, Will and others},
  journal={arXiv preprint arXiv:2006.13256},
  year={2020}
}

@article{fukushima1981neocognitron,
  title={Neocognitron--a self-organizing neural network model for a mechanism of pattern recognition unaffected by shift in position},
  author={Fukushima, Kunihiko},
  journal={NHK 放送科学基礎研究所報告},
  pages={p106--115},
  year={1981},
  publisher={NHK 放送科学基礎研究所}
}

@article{olah2017feature,
  title={Feature visualization},
  author={Olah, Chris and Mordvintsev, Alexander and Schubert, Ludwig},
  journal={Distill},
  volume={2},
  number={11},
  pages={e7},
  year={2017}
}

@article{erhan2009visualizing,
  title={Visualizing higher-layer features of a deep network},
  author={Erhan, Dumitru and Bengio, Yoshua and Courville, Aaron and Vincent, Pascal},
  journal={University of Montreal},
  volume={1341},
  number={3},
  pages={1},
  year={2009}
}

@article{Hochreiter1997lstm,
author = {Hochreiter, Sepp and Schmidhuber, J\"{u}rgen},
title = {Long Short-Term Memory},
year = {1997},
issue_date = {November 15, 1997},
publisher = {MIT Press},
address = {Cambridge, MA, USA},
volume = {9},
number = {8},
issn = {0899-7667},
url = {https://doi.org/10.1162/neco.1997.9.8.1735},
doi = {10.1162/neco.1997.9.8.1735},
abstract = {Learning to store information over extended time intervals by recurrent backpropagation takes a very long time, mostly because of insufficient, decaying error backflow. We briefly review Hochreiter's (1991) analysis of this problem, then address it by introducing a novel, efficient, gradient based method called long short-term memory (LSTM). Truncating the gradient where this does not do harm, LSTM can learn to bridge minimal time lags in excess of 1000 discrete-time steps by enforcing constant error flow through constant error carousels within special units. Multiplicative gate units learn to open and close access to the constant error flow. LSTM is local in space and time; its computational complexity per time step and weight is O. 1. Our experiments with artificial data involve local, distributed, real-valued, and noisy pattern representations. In comparisons with real-time recurrent learning, back propagation through time, recurrent cascade correlation, Elman nets, and neural sequence chunking, LSTM leads to many more successful runs, and learns much faster. LSTM also solves complex, artificial long-time-lag tasks that have never been solved by previous recurrent network algorithms.},
journal = {Neural Comput.},
month = nov,
pages = {1735–1780},
numpages = {46}
}

@article{wu2016google,
  title={Google's neural machine translation system: Bridging the gap between human and machine translation},
  author={Wu, Yonghui and Schuster, Mike and Chen, Zhifeng and Le, Quoc V and Norouzi, Mohammad and Macherey, Wolfgang and Krikun, Maxim and Cao, Yuan and Gao, Qin and Macherey, Klaus and others},
  journal={arXiv preprint arXiv:1609.08144},
  year={2016}
}

@inproceedings{shen2018natural,
  title={Natural tts synthesis by conditioning wavenet on mel spectrogram predictions},
  author={Shen, Jonathan and Pang, Ruoming and Weiss, Ron J and Schuster, Mike and Jaitly, Navdeep and Yang, Zongheng and Chen, Zhifeng and Zhang, Yu and Wang, Yuxuan and Skerrv-Ryan, Rj and others},
  booktitle={2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={4779--4783},
  year={2018},
  organization={IEEE}
}

@article{miao2020application,
  title={Application of LSTM for short term fog forecasting based on meteorological elements},
  author={Miao, Kai-chao and Han, Ting-ting and Yao, Ye-qing and Lu, Hui and Chen, Peng and Wang, Bing and Zhang, Jun},
  journal={Neurocomputing},
  volume={408},
  pages={285--291},
  year={2020},
  publisher={Elsevier}
}

@misc{sandler2019mobilenetv2,
      title={MobileNetV2: Inverted Residuals and Linear Bottlenecks}, 
      author={Mark Sandler and Andrew Howard and Menglong Zhu and Andrey Zhmoginov and Liang-Chieh Chen},
      year={2019},
      eprint={1801.04381},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@article{bertschinger2004,
author = {Bertschinger, Nils and Natschläger, Thomas},
title = {Real-Time Computation at the Edge of Chaos in Recurrent Neural Networks},
journal = {Neural Computation},
volume = {16},
number = {7},
pages = {1413-1436},
year = {2004},
doi = {10.1162/089976604323057443},
URL = {https://doi.org/10.1162/089976604323057443},
eprint = {https://doi.org/10.1162/089976604323057443}
}

@misc{laurent2016recurrent,
      title={A recurrent neural network without chaos}, 
      author={Thomas Laurent and James von Brecht},
      year={2016},
      eprint={1612.06212},
      archivePrefix={arXiv},
      primaryClass={cs.NE}
}